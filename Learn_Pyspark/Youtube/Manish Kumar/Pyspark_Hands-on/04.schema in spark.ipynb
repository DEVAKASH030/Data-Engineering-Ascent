{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bbe37c34-9e9d-4045-9195-e66b5448000f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Possible Interview Quesitons\n",
    "------------------------------\n",
    "1. How to create Schema in Pyspark?\n",
    "2. What are other ways to creating it?\n",
    "3. What is StructField and StructType in schema?\n",
    "4. What if I have header in my schema?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "696c700e-18a4-40ce-a1b2-a176114fe32f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "We can create schema in two ways:\n",
    "1.  Using StructField and StructType\n",
    "    - StructField: A StructField represents a column in a DataFrame. It has a name, a data type, and a boolean flag to indicate whether the column can be null.\n",
    "    - StructType: A StructType is a collection of StructFields. It can be used to define the structure of a DataFrame with multiple columns. \n",
    "2. Using DDL Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2edd5d36-ea17-43ea-8daa-b97a939c00d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField,StringType,IntegerType\n",
    "# Defining Schema using StructField and StructType\n",
    "flight_data_schema = StructType([\n",
    "    StructField(\"Dest_Country_Name\",StringType(),True),\n",
    "    StructField(\"Origin_Country_Name\",StringType(),True),\n",
    "    StructField(\"Count\",IntegerType(),True)\n",
    "])\n",
    "# Defining Schema using DDL Command\n",
    "# flight_data_schema = \"DEST_COUNTRY_NAME string,ORIGIN_COUNTRY_NAME string,count integer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1add7737-c979-4c26-a28d-320141df6b77",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "flight_data = spark.read.format(\"csv\")\\\n",
    "                        .option(\"header\",\"false\")\\\n",
    "                        .option(\"inferSchema\",\"false\")\\\n",
    "                        .option(\"skipRows\",1)\\\n",
    "                        .schema(flight_data_schema)\\\n",
    "                        .option(\"mode\",\"FAILFAST\")\\\n",
    "                        .load('/FileStore/tables/flight_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb8ea949-1acd-40a9-b42e-f74b35fcd4ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n|Dest_Country_Name|Origin_Country_Name|Count|\n+-----------------+-------------------+-----+\n|United States    |Romania            |15   |\n|United States    |Croatia            |1    |\n|United States    |Ireland            |344  |\n|Egypt            |United States      |15   |\n|United States    |India              |62   |\n+-----------------+-------------------+-----+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Show dataframe\n",
    "flight_data.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22410e3c-4b59-4fed-87fe-ddcaaad569f3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Dest_Country_Name: string (nullable = true)\n |-- Origin_Country_Name: string (nullable = true)\n |-- Count: integer (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Printing the schema of the dataframe\n",
    "flight_data.printSchema()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3822449828324767,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "04.schema in spark",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
