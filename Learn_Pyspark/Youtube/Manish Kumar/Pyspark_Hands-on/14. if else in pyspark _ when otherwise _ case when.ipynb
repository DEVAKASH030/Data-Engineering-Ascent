{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6b2ce3e-9371-4392-97c3-460168e70e65",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Today's Topic\n",
    "--------------\n",
    "→ case when in spark SQL.\n",
    "\n",
    "→ when otherwise in Pyspark.\n",
    "\n",
    "→ How to deal with null value?\n",
    "\n",
    "→ case when | when otherwise with multiple AND,OR condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d85aace9-0069-44d3-b5b1-e26530074e06",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "emp_data = [\n",
    "(1,'manish',26,20000,'india','IT'),\n",
    "(2,'rahul',None,40000,'germany','engineering'),\n",
    "(3,'pawan',12,60000,'india','sales'),\n",
    "(4,'roshini',44,None,'uk','engineering'),\n",
    "(5,'raushan',35,70000,'india','sales'),\n",
    "(6,None,29,200000,'uk','IT'),\n",
    "(7,'adam',37,65000,'us','IT'),\n",
    "(8,'chris',16,40000,'us','sales'),\n",
    "(None,None,None,None,None,None),\n",
    "(7,'adam',37,65000,'us','IT')\n",
    "]\n",
    "\n",
    "#Defining schema\n",
    "schema = ['id','name','age','salary','country','dept']\n",
    "\n",
    "#Creating employee dataframe\n",
    "emp_df = spark.createDataFrame(data=emp_data,schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7c3ed39-d422-4797-ba31-bd1d27247f3a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----+------+-------+-----------+\n|id  |name   |age |salary|country|dept       |\n+----+-------+----+------+-------+-----------+\n|1   |manish |26  |20000 |india  |IT         |\n|2   |rahul  |null|40000 |germany|engineering|\n|3   |pawan  |12  |60000 |india  |sales      |\n|4   |roshini|44  |null  |uk     |engineering|\n|5   |raushan|35  |70000 |india  |sales      |\n|6   |null   |29  |200000|uk     |IT         |\n|7   |adam   |37  |65000 |us     |IT         |\n|8   |chris  |16  |40000 |us     |sales      |\n|null|null   |null|null  |null   |null       |\n|7   |adam   |37  |65000 |us     |IT         |\n+----+-------+----+------+-------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Show emp_df\n",
    "emp_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "deacd761-459f-4b57-8774-a626f8dda738",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----+------+-------+-----------+--------+\n|id  |name   |age |salary|country|dept       |adult   |\n+----+-------+----+------+-------+-----------+--------+\n|1   |manish |26  |20000 |india  |IT         |Yes     |\n|2   |rahul  |null|40000 |germany|engineering|No Value|\n|3   |pawan  |12  |60000 |india  |sales      |No      |\n|4   |roshini|44  |null  |uk     |engineering|Yes     |\n|5   |raushan|35  |70000 |india  |sales      |Yes     |\n|6   |null   |29  |200000|uk     |IT         |Yes     |\n|7   |adam   |37  |65000 |us     |IT         |Yes     |\n|8   |chris  |16  |40000 |us     |sales      |No      |\n|null|null   |null|null  |null   |null       |No Value|\n|7   |adam   |37  |65000 |us     |IT         |Yes     |\n+----+-------+----+------+-------+-----------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "# Show the employees who are adult and who are not by creating new column named \"adult\"\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "emp_df.withColumn(\"adult\",when(emp_df.age > 18,\"Yes\")\n",
    "                         .when(col(\"age\") < 18,\"No\")\n",
    "                         .otherwise(\"No Value\")\n",
    "                 ).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f4ffce0-c749-4e4b-97b5-357d412ec9b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+---+------+-------+-----------+-----+\n|  id|   name|age|salary|country|       dept|adult|\n+----+-------+---+------+-------+-----------+-----+\n|   1| manish| 26| 20000|  india|         IT|  Yes|\n|   2|  rahul| 19| 40000|germany|engineering|  Yes|\n|   3|  pawan| 12| 60000|  india|      sales|   No|\n|   4|roshini| 44|  null|     uk|engineering|  Yes|\n|   5|raushan| 35| 70000|  india|      sales|  Yes|\n|   6|   null| 29|200000|     uk|         IT|  Yes|\n|   7|   adam| 37| 65000|     us|         IT|  Yes|\n|   8|  chris| 16| 40000|     us|      sales|   No|\n|null|   null| 19|  null|   null|       null|  Yes|\n|   7|   adam| 37| 65000|     us|         IT|  Yes|\n+----+-------+---+------+-------+-----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Let's consider another scenario in which we have asked to fix the age if there is any null value then go for \n",
    "# identifying which employees are adult and who are not\n",
    "emp_df.withColumn(\"age\",when(emp_df[\"age\"].isNull(),lit(19))\n",
    "                       .otherwise(col(\"age\")))\\\n",
    "      .withColumn(\"adult\",when(col(\"age\") > 18,\"Yes\")\n",
    "                         .otherwise(\"No\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9a85ec5-f6b7-4b29-a682-7d45118f418d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----+------+-------+-----------+------------+\n|  id|   name| age|salary|country|       dept|age_category|\n+----+-------+----+------+-------+-----------+------------+\n|   1| manish|  26| 20000|  india|         IT|         Med|\n|   2|  rahul|null| 40000|germany|engineering|    No Value|\n|   3|  pawan|  12| 60000|  india|      sales|       Minor|\n|   4|roshini|  44|  null|     uk|engineering|       Major|\n|   5|raushan|  35| 70000|  india|      sales|       Major|\n|   6|   null|  29|200000|     uk|         IT|         Med|\n|   7|   adam|  37| 65000|     us|         IT|       Major|\n|   8|  chris|  16| 40000|     us|      sales|       Minor|\n|null|   null|null|  null|   null|       null|    No Value|\n|   7|   adam|  37| 65000|     us|         IT|       Major|\n+----+-------+----+------+-------+-----------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "emp_df.withColumn(\"age_category\",when((col(\"age\") > 0 ) & (col(\"age\") <= 18),\"Minor\")\n",
    "                            .when((col(\"age\") > 18 ) & (col(\"age\") <= 30),\"Med\")\n",
    "                            .when((col(\"age\") > 30 ) & (col(\"age\") <= 100),\"Major\")\n",
    "                            .otherwise(\"No Value\")\\\n",
    "                 ).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86239e6a-a560-43c8-8a5a-94e8c016237d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Let's do the same thing in SparkSQL using case when\n",
    "# At first we need to convert the dataframe into temporary view\n",
    "emp_df.createOrReplaceTempView(\"employee_tbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1588d15a-4443-4b96-86f7-e76dec13d85f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----+------+-------+-----------+--------+\n|  id|   name| age|salary|country|       dept|   Adult|\n+----+-------+----+------+-------+-----------+--------+\n|   1| manish|  26| 20000|  india|         IT|     Yes|\n|   2|  rahul|null| 40000|germany|engineering|No Value|\n|   3|  pawan|  12| 60000|  india|      sales|      No|\n|   4|roshini|  44|  null|     uk|engineering|     Yes|\n|   5|raushan|  35| 70000|  india|      sales|     Yes|\n|   6|   null|  29|200000|     uk|         IT|     Yes|\n|   7|   adam|  37| 65000|     us|         IT|     Yes|\n|   8|  chris|  16| 40000|     us|      sales|      No|\n|null|   null|null|  null|   null|       null|No Value|\n|   7|   adam|  37| 65000|     us|         IT|     Yes|\n+----+-------+----+------+-------+-----------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          SELECT *,\n",
    "            CASE WHEN age > 18 THEN \"Yes\" \n",
    "                 WHEN age < 18 THEN \"No\"\n",
    "                 ELSE \"No Value\"\n",
    "            END AS Adult\n",
    "          FROM employee_tbl\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90224fef-a1f5-419b-9472-f7ec3cc78fb8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-----------+------+-------+-----------+-----+\n|id  |name   |updated_age|salary|country|dept       |Adult|\n+----+-------+-----------+------+-------+-----------+-----+\n|1   |manish |26         |20000 |india  |IT         |Yes  |\n|2   |rahul  |19         |40000 |germany|engineering|Yes  |\n|3   |pawan  |12         |60000 |india  |sales      |NO   |\n|4   |roshini|44         |null  |uk     |engineering|Yes  |\n|5   |raushan|35         |70000 |india  |sales      |Yes  |\n|6   |null   |29         |200000|uk     |IT         |Yes  |\n|7   |adam   |37         |65000 |us     |IT         |Yes  |\n|8   |chris  |16         |40000 |us     |sales      |NO   |\n|null|null   |19         |null  |null   |null       |Yes  |\n|7   |adam   |37         |65000 |us     |IT         |Yes  |\n+----+-------+-----------+------+-------+-----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Let's fix the null value and then identifying whose employees are adult and who are not\n",
    "spark.sql(\"\"\"\n",
    "        SELECT id,name,updated_age,salary,country,dept,Adult\n",
    "        FROM(\n",
    "         SELECT *,\n",
    "            CASE WHEN age IS NULL THEN 19 ELSE age END AS updated_age,\n",
    "            CASE WHEN updated_age > 18 THEN \"Yes\" ELSE \"NO\" END AS Adult\n",
    "          FROM employee_tbl\n",
    "        )\n",
    "        \"\"\").show(truncate=False)\n",
    "# We can also do it in another way like at first we need to update the table then \n",
    "# We can apply case when statement for our desired result"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "14. if else in pyspark | when otherwise | case when",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
